{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style= \"color :red\"> 생성적 적대 신경망 </span>\n",
    "- GAN : 딥러닝의 원리를 활용해 가상 이미지를 생성하는 알고리즘<br><br>\n",
    "- 진짜 같은 가짜를 만들기 위해 알고리즘 내부에서 '적대적' 경합을 진행하는 알고리즘 <br><br>\n",
    "- 한쪽은 진짜 같은 가짜를 만들고, 한쪽은 진짜와 비교하면서 경합 과정을 이용하는 원리<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style= \"color :blue\"> 가짜 제조 공장 : 생성자  </span>\n",
    "- 가상의 이미지를 만들어내는 공장 <br><br>\n",
    "- 초기엔 랜덤한 픽셀로 이뤄진 가짜 이미지를 만들고 판별자의 결과에 따라 지속적으로 업데이트 하며 점차 원하는 이미지를 만들어 낸다<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\172559\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "generator = keras.Sequential()\n",
    "generator.add(keras.layers.Dense(128*7*7,                   # 128 : 임의로 정한 노드의 수, 7*7 : 이미지의 최초 크기 \n",
    "                                 input_dim=100,             # input_dim : 100차원 크기의 랜덤 백터\n",
    "                                 activation=LeakyReLU(0.2)))# 0이하에서도 작은 값을 갖게 만드는 RELU의 보완함수  \n",
    "generator.add(keras.layers.BatchNormalization())            # 데이터의 배치를 정규분포로 만드는 배치정규화 진행\n",
    "\n",
    "\n",
    "generator.add(keras.layers.Reshape((7,7,128)))              # 합성곱신경망이 받아들일수 있는 형태로 바꿔주는 코드\n",
    "generator.add(keras.layers.UpSampling2D())                  # 이미지의 가로세로 크기를 2배씩 늘려준다 (14,14)\n",
    "\n",
    "\n",
    "generator.add(keras.layers.Conv2D(64, kernel_size = 5, padding=\"same\"))\n",
    "generator.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "generator.add(keras.layers.Activation(LeakyReLU(0.2)))\n",
    "generator.add(keras.layers.UpSampling2D())                  # 이미지의 가로세로 크기를 2배씩 늘려준다 (28,28)\n",
    "\n",
    "generator.add(keras.layers.Conv2D(1, kernel_size = 5,       # 판별자로 넘길 준비를 완료 \n",
    "                                  padding=\"same\", \n",
    "                                  activation=\"tanh\"))       # 판별자로 넘기기 전에는 tanh함수를 사용 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style= \"color :blue\"> 진위를 가려내는 장치 : 판별자  </span>\n",
    "- 생성자에서 넘어온 이미지가 가짜인지 진짜인지를 판별해주는 장치 \n",
    "- CNN구조를 그대로 가지고와서 사용하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriminator = keras.Sequential()\n",
    "descriminator.add(keras.layers.Conv2D(64, kernel_size=5, strides=2, \n",
    "                                      input_shape=(28,28,1), padding=\"same\",\n",
    "                                      activation = LeakyReLU(0.2)))\n",
    "descriminator.add(keras.layers.Dropout(0.3))\n",
    "descriminator.add(keras.layers.Conv2D(128, kernel_size=5, strides=2, \n",
    "                                      input_shape=(28,28,1), padding=\"same\",\n",
    "                                      activation = LeakyReLU(0.2)))\n",
    "descriminator.add(keras.layers.Dropout(0.3))\n",
    "descriminator.add(keras.layers.Flatten())\n",
    "descriminator.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "descriminator.compile(loss = \"binary_crossentropy\", optimizer= \"adam\")\n",
    "\n",
    "descriminator.trainable = False           # 판별이 끝나면 판별자 자신이 학습되지 않게끔 학습 기능을 꺼준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style= \"color :blue\"> 적대적 신경망 실행하기  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginput = keras.layers.Input(shape=(100,))                   # 랜덤한 100개의 백터를 생성\n",
    "dis_output = descriminator(generator(ginput))               # 출력되는 결관는 28*28크기의 이미지, 이후 판별자 모델의 값으로 사용\n",
    "gan= keras.Model(ginput, dis_output)                        # Model함수를 이용해 입력과 출력값을 가지는 GAN모델을 생성\n",
    "\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")   # 참과 거짓으 구분하는 이진함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\172559\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행할수를 선언\n",
    "def gan_train(epochs, batch_size, saving_interval):\n",
    "    import numpy as np\n",
    "    from tensorflow import keras\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os \n",
    "    \n",
    "    os.chdir(\"./혼공머신딥러닝/DeepLearning/\")\n",
    "    \n",
    "    # Mnist데이터 호출\n",
    "    (x_train, _), (_ , _) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # 차원을 지정 \n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "    \n",
    "    # 배치정규화\n",
    "    x_train = (x_train-127.5) / 127.5\n",
    "    \n",
    "    true = np.ones((batch_size, 1))             # 1의 레이블 값을 가지는 배열을 생성 (배치 길이만큼) \n",
    "    fake = np.zeros((batch_size, 1))   \n",
    "    for i in range(epochs):\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size) # 0부터 데이터 갯수까지의 숫자 중 하나를 랜덤하게 배치사이즈만큼 반복해서 가져옴\n",
    "        imgs = x_train[idx]\n",
    "        \n",
    "        # 판별자 모델에 판별을 시작 (입력값과 레이블을 받아서 딱 한번만 학습을 실시해 모델을 업데이트)\n",
    "        d_loss_real = descriminator.train_on_batch(imgs, true)  \n",
    "        \n",
    "        # 가상 이미지를 판별자에 입력하는 부분\n",
    "        noise = np.random.normal(0,1, (batch_size,100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = descriminator.train_on_batch(gen_imgs, fake)\n",
    "        \n",
    "        # 판별자와 생성자의 오차를 계산 \n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "        \n",
    "        print(\"epoch : {}, d_loss : {},  g_loss : {}\".format(i, d_loss, g_loss)) \n",
    "        \n",
    "        # 중간 과정을 이미지로 저장하는 부분, 정해진 인터벌 만큼 학습되면 그때 만든 이미지를 gan_images폴더에 저장하라는 의미\n",
    "        if i%saving_interval==0:\n",
    "            r,c = 5,5\n",
    "        noise = np.random.normal(0,1,(25,100))\n",
    "        gen_imgs = 0.5*gen_imgs+.05\n",
    "        \n",
    "        fig, axs = plt.subplots(5,5)\n",
    "        count = 0\n",
    "        for j in range(5):\n",
    "            for i in range(5):\n",
    "                axs[j,i].imshow(gen_imgs[count,:,:,0],cmap=\"gray_r\")\n",
    "                axs[j,i].axis(\"off\")\n",
    "                count += 1\n",
    "        fig.savefig(\"./gan_imgs/gan_mnist_{}.png\".format(i))\n",
    "        \n",
    "# 2000번 반복 (+1하는것에 주의)\n",
    "# 배치 크기는 32, 200번마다 결과가 저장\n",
    "gan_train(2001,32,200)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8df4e0e0c796e2e15924145e6441c62a115ba500877f31d29fc14fd3395fcd67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
